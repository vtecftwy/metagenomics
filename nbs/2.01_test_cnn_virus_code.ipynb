{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test CNN_Virus code and refactor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Original code is [here](https://github.com/MaHaoran627/CNN_Virus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Added following path: /home/vtec/projects/metagenomics/src\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import sys\n",
    "from pathlib import Path\n",
    "\n",
    "p = Path('../src').resolve().absolute()\n",
    "if p.is_dir():\n",
    "    sys.path.insert(1, str(p))\n",
    "    print(f\"Added following path: {p}\")\n",
    "else:\n",
    "    print(f\"There is no directory {p}\")\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "cnn_repo = Path('../repos/cnn_virus/').resolve()\n",
    "assert cnn_repo.is_dir()\n",
    "\n",
    "data = Path('../data/cnn_virus').resolve()\n",
    "assert data.is_dir()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preprocessing data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from preprocessing import get_learning_weights, get_params_50mer, get_kmer_from_50mer\n",
    "from preprocessing import DataGenerator_from_50mer\n",
    "\n",
    "from architecture import build_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1000, 1000, 1000)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "p2file = Path('../data/cnn_virus/50mer_validating').resolve()\n",
    "f_matrix, f_labels, f_pos = get_kmer_from_50mer(p2file, max_seqs==1000)\n",
    "len(f_matrix), len(f_labels), len(f_pos)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('AAAAAGATTTTGAGAGAGGTCGACCTGTCCTCCTAAAACGTTTACAAAAG', '71', '0')"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "i = 0\n",
    "f_matrix[i], f_labels[i], f_pos[i]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#path for the training file\n",
    "filepath_train= data /\"50mer_training\"\n",
    "#path for the validating file\n",
    "filepath_val= data / \"50mer_validating\"\n",
    "#path for the learning weights file\n",
    "filepath_weights=data / \"weights_of_classes\"\n",
    "\n",
    "\n",
    "#paths for saving model and loss\n",
    "filepath_saved=Path(\"../saved/cnn_virus\").resolve()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "d_nucl={\"A\":0,\"C\":1,\"G\":2,\"T\":3,\"N\":4}\n",
    "f_matrix,f_labels,f_pos=get_kmer_from_50mer(filepath_train, max_seqs=10000)\n",
    "f_matrix_val,f_labels_val,f_pos_val=get_kmer_from_50mer(filepath_val)\n",
    "\n",
    "params = get_params_50mer()\n",
    "d_weights=get_learning_weights(filepath_weights)\n",
    "\n",
    "training_generator = DataGenerator_from_50mer(f_matrix, f_labels, f_pos, **params)\n",
    "val_generator = DataGenerator_from_50mer(f_matrix_val, f_labels_val, f_pos_val, **params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(training_generator)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[`tf.keras.utils.Sequence`](https://www.tensorflow.org/api_docs/python/tf/keras/utils/Sequence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "tg = training_generator.__getitem__(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2, tuple, numpy.ndarray, dict)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(tg), type(tg), type(tg[0]), type(tg[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['output1', 'output2'])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inp, out_d = tg\n",
    "out_d.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((1024, 50, 5), (1024, 187), (1024, 10))"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inp.shape, out_d['output1'].shape, out_d['output2'].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[0., 0., 1., 0., 0.],\n",
       "        [0., 0., 1., 0., 0.],\n",
       "        [1., 0., 0., 0., 0.],\n",
       "        [1., 0., 0., 0., 0.]],\n",
       "\n",
       "       [[0., 1., 0., 0., 0.],\n",
       "        [0., 1., 0., 0., 0.],\n",
       "        [0., 0., 0., 1., 0.],\n",
       "        [0., 0., 1., 0., 0.]]])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inp[:2, :4, :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]], dtype=float32)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out1 = out_d['output1']\n",
    "out2 = out_d['output2']\n",
    "\n",
    "out1[:2, :10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Build model and review it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating Model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-08-30 17:57:41.629408: I tensorflow/core/platform/cpu_feature_guard.cc:151] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  SSE4.1 SSE4.2 AVX AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2022-08-30 17:57:41.632524: I tensorflow/core/common_runtime/process_util.cc:146] Creating new thread pool with default inter op setting: 2. Tune using inter_op_parallelism_threads for best performance.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_1 (InputLayer)           [(None, 50, 5)]      0           []                               \n",
      "                                                                                                  \n",
      " conv1d (Conv1D)                (None, 50, 512)      13312       ['input_1[0][0]']                \n",
      "                                                                                                  \n",
      " batch_normalization (BatchNorm  (None, 50, 512)     2048        ['conv1d[0][0]']                 \n",
      " alization)                                                                                       \n",
      "                                                                                                  \n",
      " max_pooling1d (MaxPooling1D)   (None, 25, 512)      0           ['batch_normalization[0][0]']    \n",
      "                                                                                                  \n",
      " conv1d_1 (Conv1D)              (None, 25, 512)      1311232     ['max_pooling1d[0][0]']          \n",
      "                                                                                                  \n",
      " batch_normalization_1 (BatchNo  (None, 25, 512)     2048        ['conv1d_1[0][0]']               \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " max_pooling1d_1 (MaxPooling1D)  (None, 13, 512)     0           ['batch_normalization_1[0][0]']  \n",
      "                                                                                                  \n",
      " conv1d_2 (Conv1D)              (None, 13, 1024)     3671040     ['max_pooling1d_1[0][0]']        \n",
      "                                                                                                  \n",
      " conv1d_3 (Conv1D)              (None, 13, 1024)     7341056     ['conv1d_2[0][0]']               \n",
      "                                                                                                  \n",
      " batch_normalization_2 (BatchNo  (None, 13, 1024)    4096        ['conv1d_3[0][0]']               \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " max_pooling1d_2 (MaxPooling1D)  (None, 7, 1024)     0           ['batch_normalization_2[0][0]']  \n",
      "                                                                                                  \n",
      " flatten (Flatten)              (None, 7168)         0           ['max_pooling1d_2[0][0]']        \n",
      "                                                                                                  \n",
      " dense (Dense)                  (None, 1024)         7341056     ['flatten[0][0]']                \n",
      "                                                                                                  \n",
      " batch_normalization_3 (BatchNo  (None, 1024)        4096        ['dense[0][0]']                  \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " dropout (Dropout)              (None, 1024)         0           ['batch_normalization_3[0][0]']  \n",
      "                                                                                                  \n",
      " output1 (Dense)                (None, 187)          191675      ['dropout[0][0]']                \n",
      "                                                                                                  \n",
      " concatenate (Concatenate)      (None, 1211)         0           ['dropout[0][0]',                \n",
      "                                                                  'output1[0][0]']                \n",
      "                                                                                                  \n",
      " dense_1 (Dense)                (None, 1024)         1241088     ['concatenate[0][0]']            \n",
      "                                                                                                  \n",
      " batch_normalization_4 (BatchNo  (None, 1024)        4096        ['dense_1[0][0]']                \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " output2 (Dense)                (None, 10)           10250       ['batch_normalization_4[0][0]']  \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 21,137,093\n",
      "Trainable params: 21,128,901\n",
      "Non-trainable params: 8,192\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model=build_model()\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer='adam',\n",
    "\tloss={'output1':'categorical_crossentropy','output2':'categorical_crossentropy'},\n",
    "\tmetrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/2\n",
      "10/10 [==============================] - ETA: 0s - loss: 9.5860 - output1_loss: 6.0184 - output2_loss: 3.5676 - output1_accuracy: 0.0544 - output2_accuracy: 0.1035 "
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "\n",
    "es = EarlyStopping(monitor='val_loss', patience=5, restore_best_weights=True)\n",
    "\n",
    "result = model.fit(\n",
    "    training_generator,\n",
    "\tepochs=2,\n",
    "\tverbose=1,\n",
    "\t# class_weight=d_weights,\n",
    "\tvalidation_data=val_generator,\n",
    "\tcallbacks=[es]\n",
    "\t)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.12 ('metagen')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "dfd3b4934a6b4e35dd599b40cbe0afdec143404ac9fcb14c4b97cc2a93514568"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
